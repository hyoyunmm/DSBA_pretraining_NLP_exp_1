# DSBA_pretraining_NLP_exp_1

## 1. 실험 요약
- 기본 setup
  1. lr: 5e-5
  2. scheduler: constant
  3. optimizer: adam
  4. max len: 128
- 변형
  1. model: bert-base-uncased, ModernBERT-base
  2. batch size: 16, 32
  3. dropout: 0.1, 0.3
  4. max_len: 128, 256
  5. (weight decay(정규화)/ clip(안정화): 0, 0.01/ 0.0, 1.0)

    
## 2. 결과

| 모델             | setup                             |   val\_acc |  test\_acc | test\_loss |
| -------------- | -------------------------------------- | ---------: | ---------: | ---------: |
| **BERT**       | `cls, L=128, bs=16, drop=0.1` (baseline)  |     0.8852 |     0.8852 |     0.2769 |
| **BERT**       | `mean, L=128, bs=16, drop=0.1`         |     0.8922 |     0.8776 |     0.4039 |
| **BERT**       | `cls, L=128, bs=16, drop=0.3`          |     0.8864 | **0.8872** |     0.2798 |
| **BERT**       | `cls, L=128, bs=32, wd=0.01, clip=1.0` |     0.5000 | **0.5000** |     0.6944 |
| **ModernBERT** | `cls, L=128, bs=16, drop=0.1` (baseline)  |     0.9154 | **0.9140** |     0.2155 |
| **ModernBERT** | `mean, L=128, bs=16, drop=0.1`         |     0.9124 |     0.9132 |     0.2205 |
| **ModernBERT** | `cls, L=128, bs=16, drop=0.3`          |     0.9134 |     0.9064 |     0.2198 |
| **ModernBERT** | `cls, L=128, bs=32, wd=0.01, clip=1.0` |     0.8432 | **0.8436** |     0.3585 |

| 모델             | setup                             |   val\_acc |  test\_acc | test\_loss |
| -------------- | -------------------------------------- | ---------: | ---------: | ---------: |
| **BERT**       | `cls, L=128, bs=16, drop=0.1` (baseline)  |     0.8852 |     0.8852 |     0.2769 |
| **BERT**       | `cls, L=256, bs=16, drop=0.1`          | **0.9226** | **0.9192** | **0.2114** |
| **ModernBERT** | `cls, L=128, bs=16, drop=0.1`          |     0.9154 |     0.9140 |     0.2155 |
| **ModernBERT** | `cls, L=256, bs=16, drop=0.1`          | **0.9362** | **0.9382** |     0.2746 |

## 3. 분석
- 어떤 모델이 좋은가? => ModernBERT
  - 파라미터 조정 시?
    1. 같은 파라미터라면 늘 ModernBERT가 더 우수
    2. 동일 모델(및 단순 실험 내 비교) 내에서 일관되게 유의미성을 보인 것은 cls > mean
    4. 모델마다 dropout의 효과는 달라보임. 과적합과 학습력 저하의 어떤 tradeoff.. (dropout 만을 비교하려면 추가 실험이 필요)
- 왜 좋은가?
  - ModernBERT: 구조적 차이 덕분이라고 생각 (오히려 잡음을 주는 NSP task의 제거라던가, 오래 학습한다던가, 동적 마스킹 등)
  - max_len: 해당 데이터셋에선 장문 정보가 많았음을 유추
  - cls: 첫 토큰의 cls값을 사용하는데 대표성이 높은 듯, 그런데 mean이 유리한 상황은 없을지에 대한 궁금증
  - 번외 > acc ⬆️ 인데 loss ⬆️ 인 이유? => 정답을 맞추긴 하는데 확신이 낮음 calibration 저하, testset에 따라 성능 지표 적절한 선택의 필요성! (IMDb는 균형 데이터이므로 test acc 비교가 유의미)
  - 번외 > 왜 wd, clip을 양수로 했을 때 취약한가? => 배치 늘렸을때 학습률도 건드린다던가, 조합을 잘 맞춰야 했었음
- 코드 작성 시 주의해야 할 점은 무엇인가?
  - 이번 실험에서는 서버 작업이 가미되어 실험 환경 세팅에 큰 시간을 소모했기 때문에, (서버와의 연결이 끊기면 실험이 종료되어 계속 반복 작업을 한다던가 등) 비효율적인 기본 작업을 개선해야했다.
  (tmux, 로컬 terminal 이용, grid exp 실행을 위한 bash 파일 작업, epoch 1 작업 성공 log 체크 후 epoch 수 늘리기 등)
  - 모델 별 인자가 다르다던가, 한 실험으로 일괄적으로 돌리기 위해 optional 하게 로직을 짜야했음.
